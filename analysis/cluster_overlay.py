import pandas as pd
import numpy as np
from scipy.stats import ttest_ind as t
from itertools import combinations

'''
overlays clusters (generated by model) on top of lineup data

generates statistical significance of every cluster combination

'''



######################################
#read in the yearly lineup data that should be merged for analysis
raw_lineup_data_2016_17 = pd.read_csv('~/capstone_project/data/lineup_data_2016_17.csv')
raw_lineup_data_2015_16 = pd.read_csv('~/capstone_project/data/lineup_data_2015_16.csv')
raw_lineup_data_2014_15 = pd.read_csv('~/capstone_project/data/lineup_data_2014_15.csv')
raw_lineup_data_2013_14 = pd.read_csv('~/capstone_project/data/lineup_data_2013_14.csv')
raw_lineup_data_2012_13 = pd.read_csv('~/capstone_project/data/lineup_data_2012_13.csv')
# raw_lineup_data_2012_13 = pd.read_csv('~/capstone_project/data/lineup_data_2012_13.csv')

raw_lineup_data_dfs = [raw_lineup_data_2016_17,raw_lineup_data_2015_16, raw_lineup_data_2014_15,raw_lineup_data_2013_14,raw_lineup_data_2012_13]

#read in the player clusters (model output)
player_clusters = pd.read_csv('~/capstone_project/data/t_sne_clusters.csv')
#####################################



def add_clusters_to_lineups(raw_lineup_data_dfs, clusters_df):
    """
    INPUT:
    1) a list of dataframes of lineup data by season (ie one or more seasons)
    2) a dataframe of cluster assignments per player_id

    OUTPUT:
    1) a dataframe of every lineup transformed into cluster combinations

    """
    #convert the lineup ids to sorted list of ints
    lineups_df = raw_lineup_data_dfs[0]
    for i, df in enumerate(raw_lineup_data_dfs):
        if i > 0:
            lineups_df = lineups_df.append(df, ignore_index= True)

    lineup_ids = []
    for i in xrange(lineups_df.shape[0]):
        lineup = lineups_df['lineup_ids'].iloc[i].replace(' ','').split('-')
        lineup = [int(x) for x in lineup]
        lineup.sort()
        lineup_ids.append(lineup)
    lineups_df['lineup_ids'] = lineup_ids

    #create list of players that have cluster assignments
    players_with_cluster  = clusters_df.player_id.tolist()

    #create list to hold lists of clusters (later append this to df as a Series)
    cluster_lst = []
    #iterate over each line in lineup_data
    for i in xrange(lineups_df.shape[0]):
        #index into the linup_ids attribute
        lineup = lineups_df['lineup_ids'].iloc[i]

        #create empty temp list to hold clusters for each row
        clusters_temp = []

        #iterate over the lineup_ids list
        for player_id in lineup:
            print player_id
            if player_id in players_with_cluster:
                #for each id in the list to pull the corresponding cluster from player_clusters
                player_cluster = clusters_df['cluster'][clusters_df['player_id'] == player_id]
                clusters_temp.append(int(player_cluster.iloc[0]))
            else:
                clusters_temp.append('X')
        #add the cluster to the temp list
        clusters_temp.sort()
        clusters_temp = [str(x) for x in clusters_temp]
        #add the list to the list of clusters
        cluster_lst.append(clusters_temp)
    #add the whole list of clusters to the df
    lineups_df['clusters'] = cluster_lst
    return lineups_df

def get_stat_significance(cluster_lineup_df, lineup_minute_min):
    #takes in file/df of all cluster combinations
    clusters_lineups = cluster_lineup_df.copy()

    #convert clusters to str so they can be grouped, drop unnecessary columns
    #drop any cluster combos containing players that aren't being included in analyis (ie low minutes played)
    #group by lineup ids (to aggregate lineup stats over multiple seasons)
    #create net rating column and net per min
    clusters_str = clusters_lineups['clusters'].apply(lambda x: ','.join(x))
    clusters_lineups['lineup_ids'] = clusters_lineups['lineup_ids'].apply(lambda x: map(str, x))
    lineup_ids_str = clusters_lineups['lineup_ids'].apply(lambda x: ','.join(x))
    clusters_lineups['clusters'] = clusters_str
    clusters_lineups['lineup_ids'] = lineup_ids_str
    clusters_lineups = clusters_lineups[['lineup_ids','lineup_names','clusters','points_scored','points_allowed','MIN_TOT']]
    clusters_lineups = clusters_lineups[clusters_lineups.clusters.str.contains("X") == False]
    # clusters_lineups['lineup_ids'] = clusters_lineups['lineup_ids'].apply(lambda x: map(int, x))
    clusters_lineups = clusters_lineups.groupby(['lineup_ids', 'clusters','lineup_names']).sum()
    clusters_lineups.reset_index(inplace=True)
    clusters_lineups = clusters_lineups[clusters_lineups.MIN_TOT >= lineup_minute_min]

    #create set of all unique cluster combos
    unique_cluster_combos = sorted(list(set(clusters_lineups['clusters'].tolist())))
    clusters_lineups['net'] = clusters_lineups['points_scored'] - clusters_lineups['points_allowed']
    clusters_lineups['net_per_min'] = clusters_lineups['net']/clusters_lineups['MIN_TOT']
    net_min_cluster_combo_all = clusters_lineups['net_per_min'].tolist()

    aggregated_cluster_combos = clusters_lineups[['clusters','net','MIN_TOT']].groupby('clusters').sum()
    aggregated_cluster_combos['net_per_min'] = aggregated_cluster_combos['net']/aggregated_cluster_combos['MIN_TOT']
    aggregated_cluster_combos.reset_index(inplace = True)
    aggregated_cluster_combos.sort('clusters', inplace = True)
    unique_c_combos_net_min = aggregated_cluster_combos['net_per_min'].tolist()

    #create an array over the df of the net_plus_minus/min for each lineup


    #iterate over the set, index into the df for that cluster combo (eg filter out everything else)
    # create an array representing the net_plus_minus/min for that cluster combo
    # run a welsh's t-test for each using the cluster combo array and the overall array
    #store scores

    lst_of_dicts = []
    for cluster, net in zip(unique_cluster_combos, unique_c_combos_net_min):
        net_min_cluster_combo = clusters_lineups['net_per_min'][clusters_lineups.clusters == cluster].tolist()
        cluster_combo_min = clusters_lineups[['clusters','MIN_TOT']].groupby('clusters').sum()
        cluster_combo_min.reset_index(inplace = True)
        cluster_combo_min = cluster_combo_min['MIN_TOT'][cluster_combo_min['clusters'] == cluster].sum()
        t_score, p_val = t(net_min_cluster_combo_all,net_min_cluster_combo, equal_var = False)
        temp_dict = {'cluster_combo':cluster,'min':cluster_combo_min,'t_score':t_score, 'p_val':round(p_val,5), 'net_per_min':net}
        lst_of_dicts.append(temp_dict)

    cluster_combo_scores = pd.DataFrame(lst_of_dicts)
    cluster_combo_scores = cluster_combo_scores.sort('net_per_min')
    cluster_combo_scores = cluster_combo_scores[cluster_combo_scores['p_val'] <= .1]
    cluster_combo_scores = cluster_combo_scores[cluster_combo_scores['min'] >= 75]
    cluster_combo_scores.sort('net_per_min',inplace = True, ascending = False )
    cluster_combo_scores.drop('min', inplace = True, axis = 1)

    aggregated_cluster_combos = aggregated_cluster_combos.sort('net_per_min', ascending = False)
    aggregated_cluster_combos = aggregated_cluster_combos[aggregated_cluster_combos.MIN_TOT >= 60]

    clusters_lineups.to_csv('~/capstone_project/data/clusters_lineups.csv')

    return aggregated_cluster_combos, clusters_lineups, cluster_combo_scores


def get_three_combo(clusters_lineups_df):
    clusters_lineups = clusters_lineups_df
    lineups = clusters_lineups_df.clusters.tolist()

    lineups_int = []
    for lineup in lineups:
        lineup = lineup.split(',')
        lineup = [int(s) for s in lineup]
        lineup = sorted(lineup)
        lineups_int.append(lineup)
    lineups_int = sorted(lineups_int)

    lst_of_indicies = []
    cluster_combos = [x for x in range(10)]
    combos = combinations(cluster_combos, 3)
    combos = map(list, combos)
    combos = sorted(list(combos))

    # for combo in combos:
    #     For lineup in
    return lineups_int




if __name__ == '__main__':
    # lineup_cluster_df = add_clusters_to_lineups(raw_lineup_data_dfs,player_clusters)
    # aggregated_cluster_combos, clusters_lineups, cluster_combo_scores = get_stat_significance(lineup_cluster_df,15)
    clusters_lineups = pd.read_csv('~/capstone_project/data/clusters_lineups.csv')
    test = get_three_combo(clusters_lineups)
